{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import m2models\n",
    "from m2models.trainers import EnergyTrainer\n",
    "from m2models import models     \n",
    "from m2models.common import logger\n",
    "from m2models.common.utils import setup_logging\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data and process data to lmdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scripts for download and preprocess data into lmdb is under scripts directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.download_data import get_data\n",
    "\n",
    "np.random.seed(42)\n",
    "get_data(\n",
    "    datadir=os.path.join(os.path.dirname(m2models.__path__[0]), \"data\"),\n",
    "    property=qmof:bandgap,\n",
    "    task=jarvis,\n",
    "    split=random,\n",
    "    seed=42,\n",
    "    data_frac=[0.6, 0.2, 0.2],\n",
    "    del_intmd_files=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before training, create a config file to specify the dataset using, task performing, model to be trained, and optimizer. Below is an example of config file for training. More examples are under configs directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "          {'src': 'data/jarvis/qmof:bandgap/random_train/'},\n",
    "          {'src': 'data/jarvis/qmof:bandgap/random_valid/'},\n",
    "          {'src': 'data/jarvis/qmof:bandgap/random_test/'}\n",
    "          ]\n",
    "\n",
    "task = {\n",
    "  \"dataset\": \"lmdb\",\n",
    "  \"description\": \"Regressing the energies\",\n",
    "  \"type\": \"regression\",\n",
    "  \"metric\": \"mae\",\n",
    "}\n",
    "\n",
    "model = {\n",
    "  \"name\": \"cgcnn\",\n",
    "  \"atom_embedding_size\": 128,\n",
    "  \"fc_feat_size\": 256,\n",
    "  \"num_fc_layers\": 4,\n",
    "  \"num_graph_conv_layers\": 5,\n",
    "  \"cutoff\": 6.0,\n",
    "  \"num_gaussians\": 100,\n",
    "  \"regress_forces\": False,\n",
    "  \"use_pbc\": True,\n",
    "  \"otf_graph\": False,\n",
    "}\n",
    "\n",
    "optim = {\n",
    "  \"batch_size\": 8,\n",
    "  \"eval_batch_size\": 8,\n",
    "  \"num_workers\":  4,\n",
    "  \"lr_initial\": 0.0001,\n",
    "  \"lr_gamma\": 0.1,\n",
    "  \"lr_milestones\": [5000000],\n",
    "  \"warmup_steps\": -1,\n",
    "  \"warmup_factor\": 1.0,\n",
    "  \"max_epochs\": 10,\n",
    "  \"eval_every\": 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a trainer according to the task performing. In this example, we are using energy trainer. More trainers for other tasks can be find in m2models/trainers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EnergyTrainer(\n",
    "    task=task,\n",
    "    model=copy.deepcopy(model),\n",
    "    dataset=dataset,\n",
    "    optimizer=optim,\n",
    "    identifier=\"qmof-bandgap-03\",\n",
    "    logger=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCPDataParallel(\n",
       "  (module): CGCNN(\n",
       "    (embedding_fc): Linear(in_features=92, out_features=128, bias=True)\n",
       "    (convs): ModuleList(\n",
       "      (0): CGCNNConv()\n",
       "      (1): CGCNNConv()\n",
       "      (2): CGCNNConv()\n",
       "      (3): CGCNNConv()\n",
       "      (4): CGCNNConv()\n",
       "    )\n",
       "    (conv_to_fc): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (fcs): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Softplus(beta=1, threshold=20)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Softplus(beta=1, threshold=20)\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Softplus(beta=1, threshold=20)\n",
       "    )\n",
       "    (fc_out): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (distance_expansion): GaussianSmearing()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('M2Hub_test02')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc797cb97a6ac60a1468db7188467283f5b6290b274db917e64142edae34c400"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
